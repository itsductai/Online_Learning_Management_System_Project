{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a744340",
   "metadata": {},
   "source": [
    "# =============================================\n",
    "## GHI CHÚ TỔNG QUAN (NOTE – DÀNH CHO KAGGLE)\n",
    "# =============================================\n",
    " **Mục tiêu**\n",
    " - Fine-tune mô hình T5 (seq2seq) cho bài toán Text-to-SQL trên Kaggle.\n",
    " - Dùng dataset công khai (b-mc2/sql-create-context, Clinton/Text-to-sql-v1, knowrohit07/know_sql),\n",
    " sau đó trộn, tiền xử lý (tokenize), huấn luyện, lưu mô hình.\n",
    " - Không thay đổi logic cốt lõi; chỉ bổ sung chú thích chi tiết.\n",
    "\n",
    " **Luồng chính**\n",
    " 1) Cài đặt thư viện → Import.\n",
    " 2) Nạp/ghép dataset có sẵn → lưu cache (merged_dataset).\n",
    " 3) Tiền xử lý (tokenize) → lưu cache (tokenized_datasets).\n",
    " 4) Kiểm thử zero-shot (baseline) trên model gốc.\n",
    " 5) Huấn luyện full fine-tune → lưu mô hình đã fine-tune.\n",
    " 6) Kiểm thử lại với mô hình fine-tuned + đánh giá (ROUGE) mẫu nhỏ.\n",
    " 7) Đóng gói mô hình (zip) để tải xuống / dùng về sau.\n",
    "\n",
    " **Đầu ra (sản phẩm)**\n",
    " - Thư mục model đã fine-tune: /kaggle/working/sql_t5_finetuned\n",
    " - Có thể nạp về app (FastAPI/Flask/.NET-bridge) bằng from_pretrained(\"/kaggle/working/sql_t5_finetuned\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aecfc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.0.0rc2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.3.1)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.1\n",
      "    Uninstalling pyarrow-19.0.1:\n",
      "      Successfully uninstalled pyarrow-19.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pyarrow-21.0.0\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện datasets nếu chưa có\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b3f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.1.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.0.0rc2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (0.19.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer-slim->huggingface-hub>=0.7.0->evaluate) (8.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.7.0->evaluate) (1.3.1)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện evaluate\n",
    "!pip install evaluate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2fdf32",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 2) IMPORT CÁC THƯ VIỆN CẦN THIẾT\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a0466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124 True\n"
     ]
    }
   ],
   "source": [
    "import torch; \n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6d186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 10:29:36.576791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760610576.808863      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760610576.881376      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk # Dataset Huggingface\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer # Model và Tokenizer cho trainning\n",
    "import torch # Thư viện PyTorch tăng tốc độ xử lý GPU, tensor\n",
    "import time # Ghi thời gian trainning\n",
    "import evaluate # Thư viện evaluate để đánh giá mô hình (BLEU, ROUGE)\n",
    "import pandas as pd # Thư viện pandas để xử lý dữ liệu dạng bảng/kết quả\n",
    "import numpy as np # Thư viện numpy để xử lý mảng\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Bỏ qua các cảnh báo không cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd630f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e02be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (1.0.0rc2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 1.0.0rc2\n",
      "    Uninstalling huggingface-hub-1.0.0rc2:\n",
      "      Successfully uninstalled huggingface-hub-1.0.0rc2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface_hub-0.35.3\n"
     ]
    }
   ],
   "source": [
    "# Import thư viện transformers và huggingface_hub\n",
    "!pip install transformers huggingface_hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # Model và Tokenizer T5\n",
    "\n",
    "import os # Thư viện os để thao tác với hệ thống tệp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51294b0e",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 3) CẤU HÌNH ĐƯỜNG DẪN VÀ THIẾT BỊ\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_model_path = '/kaggle/working/' # Đường dẫn lưu model trên Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a11b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cuda.is_available() # Kiểm tra GPU có sẵn không, trả về True hoặc False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf94eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849a488bafa448c2a03a95f4ee2a03da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 20 files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278264752355497c9f189633140ce139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41397598e65948399b42b59af11ce33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048338479360417485f7c85590861d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/537 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1f0ec454134363a3445697ab577b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0be4791bc5415f8a90368dad7400a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flax_model.msgpack:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4899dd1006ac474ea0c3e37a7f5336bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d988fb0e5dc4a119b73d284709dbd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_model.onnx:   0%|          | 0.00/232M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ef1095e9674a1694995ff4d312f49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_model_merged.onnx:   0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6448c76cc2495daaec90ef89a64902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_model_quantized.onnx:   0%|          | 0.00/58.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cce1f497b14bcba9e6253926a91d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_with_past_model_quantized.o(…):   0%|          | 0.00/55.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b786ad3a6db449b8d0d04b824c33470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_model_merged_quantized.onnx:   0%|          | 0.00/58.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5518dea14c48abb5a3c206b3b8e917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/decoder_with_past_model.onnx:   0%|          | 0.00/220M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed67ffbef66444658ff4a64ab5560e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/encoder_model.onnx:   0%|          | 0.00/141M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7fc60b2986244a3a82973fbd33371a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "onnx/encoder_model_quantized.onnx:   0%|          | 0.00/35.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95695168efd642ffb6e90652446745e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a763ef125344429a39e56fe274f474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rust_model.ot:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cbde7235cd440d68bfd4d494101fb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001ccf36ad5947f8b2765af91063f557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fa8155df16438a9b4a812dfb73c4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632a239f85f14e119479bfc67166c9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1) Tải snapshot repo model về LOCAL FOLDER (chỉ gọi API 1 lần, không đụng 'additional_chat_templates')\n",
    "#   - repo_id 't5-small' sẽ redirect về 'google-t5/t5-small'\n",
    "local_dir = snapshot_download(repo_id=\"t5-small\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='t5-small' # Tên model nền; code gốc chọn t5-small cho baseline/finetune\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(local_dir, local_files_only=True)\n",
    "\n",
    "# Trên Kaggle GPU có thể dùng bfloat16, còn local CPU thì để mặc định FP32\n",
    "if device == \"cuda\":\n",
    "    original_model = T5ForConditionalGeneration.from_pretrained(\n",
    "        model_name, torch_dtype=torch.bfloat16\n",
    "    ).to(device)\n",
    "else:\n",
    "    original_model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"You are using the default legacy behaviour\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9525d407",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 4) NẠP/CHUẨN BỊ DATASET (CÓ CACHE)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a229def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b698896b3848ed8dc2bedd2937280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4659e83ab54512abfbdc53b6d3f8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sql_create_context_v4.json:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e09094d82c4a97a3e393603b076d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5308f0f28b84e71bb87aaee9ce8e0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/118 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583108142d714e0294638d590520fe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "texttosqlv2.jsonl:   0%|          | 0.00/635M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9246a6c1c134655b40851846692f732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/262208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbb60e38284468d9a2144c1c25586a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e67144a81147ff8cd8cb499a9bc1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "know_sql_val3{ign}.json:   0%|          | 0.00/13.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fadcf1eea654690b30678b1df50a568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/49456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096f6d2a1334455e80752acb56e73ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/118695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43f406fddf74fbc85ed275d7b908918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfda9d8eb3f846eda3444a1a0f19e236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged and Saved Dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 118695\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 14835\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 14838\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cố gắng nạp dataset đã merge sẵn từ cache \"merged_dataset\" để tiết kiệm thời gian\n",
    "try:\n",
    "    dataset = load_from_disk(\"merged_dataset\")\n",
    "    print(\"Loaded Merged Dataset\")\n",
    "except:\n",
    "    # Nếu không có cache, tiến hành tải và merge 3 dataset công khai và chia split thủ công\n",
    "    \n",
    "    # 4.1) b-mc2/sql-create-context (chứa question/context/answer)\n",
    "    dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]') # 80% train\n",
    "    dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]') # 10% test\n",
    "    dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]') # 10% validation\n",
    "\n",
    "    # 4.2) Clinton/Text-to-sql-v1 (đổi tên cột để thống nhất question/context/answer)\n",
    "\n",
    "    dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]') # 80% train\n",
    "    dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text']) # Bỏ cột không cần thiết\n",
    "    dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'}) # Đổi tên cột cho thống nhất với dataset_scc\n",
    "    \n",
    "    dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]') # 10% test\n",
    "    dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text']) \n",
    "    dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'}) \n",
    "    dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]') # 10% validation\n",
    "    dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
    "    dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "    # 4.3) knowrohit07/know_sql (đổi tên cột để thống nhất question/context/answer)\n",
    "    dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
    "    dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
    "    dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
    "\n",
    "    # 4.4) Ghép 3 nguồn lại bằng interleave_datasets để tăng đa dạng dữ liệu\n",
    "    dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
    "                            'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
    "                            'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n",
    "\n",
    "    # Lưu dataset đã merge vào cache \"merged_dataset\" để lần sau dùng lại\n",
    "    dataset.save_to_disk(\"merged_dataset\")\n",
    "    print(\"Merged and Saved Dataset\")\n",
    "\n",
    "dataset # Hiển thị thông tin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79baf4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT date FROM table_name_11 WHERE away_team = \"essendon\"',\n",
       " 'question': 'On what Date did the Away team essendon play?',\n",
       " 'context': 'CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['test'][0] # Kiểm tra một mẫu trong tập test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e85ea",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 5) HÀM TIỀN XỬ LÝ (TOKENIZE) + TẠO PROMPT\n",
    "# ==============================\n",
    "\n",
    "Ở bước này, cần chuyển đổi các bộ dữ liệu thành dạng hướng dẫn rõ ràng cho mô hình ngôn ngữ lớn (LLM).\n",
    "\n",
    "Sau đó, tiến hành tiền xử lý dữ liệu prompt-response bằng cách mã hóa (tokenize) để lấy ra các input_ids phục vụ cho quá trình huấn luyện.\n",
    "\n",
    "Ghi chú: Chuyển dữ liệu dạng (context/question/answer) → (input_ids/labels) cho T5\n",
    " Prompt dạng:\n",
    " Tables:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdded5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded tokenized dataset from cache.\n"
     ]
    }
   ],
   "source": [
    "# def tokenize_function(example): # Hàm tokenize_function để tiền xử lý dữ liệu\n",
    "\n",
    "# #     print(len(example[\"question\"]))\n",
    "# # # Tiền tố/giữa/hậu cho prompt để mô hình rõ cấu trúc đầu vào\n",
    "#     start_prompt = \"Tables:\\n\" # Bắt đầu với Tables:\n",
    "#     middle_prompt = \"\\n\\nQuestion:\\n\" # Giữa là Question:\n",
    "#     end_prompt = \"\\n\\nAnswer:\\n\" # Kết thúc với Answer:\n",
    "\n",
    "#     # Ghép promt theo từng cặp context/question\n",
    "#     data_zip = zip(example['context'], example['question']) # Ghép cặp context và question\n",
    "#     prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip] # Tạo prompt hoàn chỉnh\n",
    "    \n",
    "#     # Mã hoá prompt → input_ids (padding/truncation theo mặc định max_length của tokenizer)\n",
    "#     example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids # Tokenize prompt\n",
    "    \n",
    "#     # Mã hoá câu trả lời (answer) → labels\n",
    "#     example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids # Tokenize answer\n",
    "# #     print(prompt[0])\n",
    "# #     print()\n",
    "\n",
    "#     return example\n",
    "\n",
    "# # Ghi chú: Hàm trên sẽ được áp vào cả 3 split (train/validation/test) bằng map(batched=True)\n",
    "# # batched=True để xử lý theo lô, tăng tốc độ xử lý\n",
    "# # Hàm tokenize_function xử lý tất cả dữ liệu trên tất cả các split theo lô.\n",
    "\n",
    "\n",
    "# # Cố gắng nạp dataset đã tokenized sẵn từ cache \"tokenized_datasets\" để tiết kiệm thời gian\n",
    "# try:\n",
    "#     # Thử nạp từ cache nếu đã tokenized trước đó\n",
    "#     tokenized_datasets = load_from_disk(\"tokenized_datasets\") \n",
    "#     print(\"Loaded Tokenized Dataset\")\n",
    "# except:\n",
    "#     # Nếu chưa có cache, thực thi map → loại bỏ cột thừa → lưu cache\n",
    "#     tokenized_datasets = dataset.map(tokenize_function, batched=True) # Áp dụng hàm tokenize_function cho toàn bộ dataset\n",
    "#     tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer']) # Loại bỏ cột thừa để tiết kiệm bộ nhớ\n",
    "\n",
    "#     # Lưu dataset đã tokenized vào cache \"tokenized_datasets\" để lần sau dùng lại\n",
    "#     tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
    "#     print(\"Tokenized and Saved Dataset\")\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "MAX_INPUT_LEN = 256   # độ dài tối đa của prompt (Tables + Question)\n",
    "MAX_LABEL_LEN = 128   # độ dài tối đa của Answer/SQL\n",
    "\n",
    "def tokenize_function(example):\n",
    "    # Tạo prompt chuẩn dạng:\n",
    "    # Tables: [schema]\n",
    "    # Question: [natural language question]\n",
    "    # Answer: [SQL query]\n",
    "    start_prompt = \"Tables:\\n\"\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\"\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\"\n",
    "\n",
    "    # Ghép từng cặp context + question thành một prompt hoàn chỉnh\n",
    "    prompt = [\n",
    "        start_prompt + context + middle_prompt + question + end_prompt\n",
    "        for context, question in zip(example[\"context\"], example[\"question\"])\n",
    "    ]\n",
    "\n",
    "    # Tokenize đầu vào và đầu ra với padding động + cắt độ dài hợp lý\n",
    "    model_inputs = tokenizer(\n",
    "        prompt,\n",
    "        padding=False,  # 🔻 không ép về max_length\n",
    "        truncation=True,\n",
    "        max_length=MAX_INPUT_LEN,\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        example[\"answer\"],\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LABEL_LEN,\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 🔹 TẠO DATASET TOKENIZED (CÓ CACHE)\n",
    "# =========================================================\n",
    "try:\n",
    "    tokenized_datasets = load_from_disk(\"tokenized_datasets\")\n",
    "    print(\"✅ Loaded tokenized dataset from cache.\")\n",
    "except:\n",
    "    tokenized_datasets = dataset.map(\n",
    "        tokenize_function, batched=True, remove_columns=[\"question\", \"context\", \"answer\"]\n",
    "    )\n",
    "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
    "    print(\"✅ Tokenized dataset saved to cache.\")\n",
    "\n",
    "# Data collator → tự padding theo batch, giúp tiết kiệm VRAM\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=finetuned_model,\n",
    "    padding=\"longest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a78136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test', 'validation'])\n",
      "dict_keys(['input_ids', 'labels'])\n",
      "[4398, 7, 10, 205, 4386, 6048, 332, 17098, 819, 41]\n",
      "[3, 23143, 14196, 2847, 17161, 599, 1935, 61, 21680, 819]\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 118695\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14838\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị thông tin tokenized_datasets kiểm tra nhanh khóa/cấu trúc trước khi train\n",
    "print(tokenized_datasets.keys()) # Hiển thị các split có trong tokenized_datasets\n",
    "print(tokenized_datasets['train'][0].keys()) # Hiển thị các khóa trong một mẫu của tập train\n",
    "print(tokenized_datasets['train'][0]['input_ids'][:10]) # Hiển thị 10 token đầu tiên của input_ids\n",
    "print(tokenized_datasets['train'][0]['labels'][:10]) # Hiển thị 10 token đầu tiên của labels\n",
    "print(tokenized_datasets) # Hiển thị thông tin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b37e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (118695, 2)\n",
      "Validation: (14838, 2)\n",
      "Test: (14835, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 118695\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14838\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\") # In kích thước tập train (số mẫu, số cột)\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\") # In kích thước tập validation (số mẫu, số cột)\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\") # In kích thước tập test (số mẫu, số cột)\n",
    "\n",
    "print(tokenized_datasets) # Hiển thị thông tin tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbb28b",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 7) KIỂM THỬ ZERO-SHOT VỚI MODEL GỐC (BASELINE)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d60ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Your input prompt here\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "Expected human response here\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Votre prompt here\n"
     ]
    }
   ],
   "source": [
    "import torch # Thư viện PyTorch tăng tốc độ xử lý GPU, tensor\n",
    "\n",
    "# Định nghĩa prompt & answer mẫu để test nhanh (người dùng cần thay bằng ví dụ thật)\n",
    "prompt = \"Your input prompt here\"  # Ví dụ: Tables + Question (cần thay bằng prompt thực)\n",
    "answer = \"Expected human response here\"  # Ví dụ: câu SQL chuẩn tương ứng (đáp án chuẩn)\n",
    "\n",
    "# Đảm bảo model và input cùng trên một thiết bị (CPU hoặc GPU) nếu có\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Di chuyển model sang thiết bị phù hợp (device = CPU hoặc GPU)\n",
    "original_model.to(device)\n",
    "\n",
    "# Tokenize đầu vào input và chuyển nó sang cùng thiết bị với model\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "# Sinh đầu ra zero-shot từ model gốc (chưa fine-tune)\n",
    "output = tokenizer.decode( # dùng tokenizer.decode để giải mã token thành text\n",
    "    original_model.generate( # dùng phương thức generate để sinh text\n",
    "        inputs[\"input_ids\"], # input_ids của prompt đã tokenized\n",
    "        max_new_tokens=200, # Giới hạn tối đa 200 token mới sinh\n",
    "    )[0], # Lấy mảng token đầu tiên trong batch (ở đây batch size=1)\n",
    "    skip_special_tokens=True # Bỏ qua các token đặc biệt khi giải mã\n",
    ")\n",
    "\n",
    "# In kết quả zero-shot baseline\n",
    "dash_line = '-' * 100 \n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}') \n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387d62a",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 8) HUẤN LUYỆN FULL FINE-TUNE (KAGGLE GPU)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589eb0",
   "metadata": {},
   "source": [
    "#### 5e-3\n",
    "\n",
    "Thời gian huấn luyện      = 2 giờ 49 phút 1 giây trên laptop sử dụng notebook Kaggle (PC cá nhân không đủ bộ nhớ CUDA để huấn luyện với tập dữ liệu lớn)\n",
    "\n",
    "Training Loss   = 0.023100\n",
    "\n",
    "Validation Loss = 0.013285\n",
    "\n",
    "---\n",
    "\n",
    "**Giải thích:**\n",
    "\n",
    "- **5e-3**: Đây là giá trị learning rate (tốc độ học) được sử dụng khi huấn luyện mô hình. Giá trị này ảnh hưởng đến tốc độ cập nhật trọng số của mô hình trong quá trình học.\n",
    "- **Thời gian huấn luyện**: Tổng thời gian để hoàn thành quá trình fine-tune mô hình trên GPU của Kaggle. Nếu dùng máy cá nhân (PC) không có đủ bộ nhớ CUDA thì sẽ không thể huấn luyện với tập dữ liệu lớn.\n",
    "- **Training Loss**: Độ lỗi (loss) trên tập huấn luyện. Giá trị càng nhỏ chứng tỏ mô hình học tốt trên dữ liệu huấn luyện.\n",
    "- **Validation Loss**: Độ lỗi trên tập kiểm thử (validation). Giá trị này dùng để đánh giá khả năng tổng quát hóa của mô hình trên dữ liệu chưa từng thấy. Nếu validation loss thấp và gần với training loss, mô hình không bị overfit.\n",
    "\n",
    "**Kết luận:**  \n",
    "Mô hình đã được huấn luyện với tốc độ học 5e-3, thời gian gần 3 tiếng trên GPU của Kaggle. Kết quả training loss và validation loss đều thấp, chứng tỏ mô hình học tốt và có khả năng tổng quát hóa tốt trên dữ liệu kiểm thử."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nếu trước đó bạn đã dùng snapshot_download(...) và có biến local_dir,\n",
    "# thì ưu tiên nạp model/tokenizer từ local_dir; nếu không thì dùng tên model gốc.\n",
    "base_source = local_dir if 'local_dir' in globals() else model_name  # ví dụ: \"google-t5/t5-small\" hoặc \"t5-small\"\n",
    "\n",
    "\n",
    "# ===== Cố gắng nạp model đã fine-tune nếu có =====\n",
    "try:\n",
    "    # Nạp lại mô hình đã fine-tune (thư mục local do bạn save_pretrained trước đó)\n",
    "    finetuned_model = T5ForConditionalGeneration.from_pretrained(\"finetuned_model_2_epoch\").to(device)\n",
    "\n",
    "    # Nạp tokenizer đi kèm checkpoint fine-tune (đảm bảo đồng bộ vocab)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"finetuned_model_2_epoch\")\n",
    "\n",
    "    to_train = False  # Có model rồi → không cần train lại\n",
    "\n",
    "except Exception as e:\n",
    "    # Không có checkpoint fine-tune → nạp model nền để fine-tune\n",
    "    to_train = True\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        # Trên Kaggle GPU có thể dùng bfloat16 để tiết kiệm VRAM/tăng tốc\n",
    "        finetuned_model = T5ForConditionalGeneration.from_pretrained(\n",
    "            base_source, torch_dtype=torch.bfloat16\n",
    "        ).to(device)\n",
    "    else:\n",
    "        # Trên CPU giữ FP32 mặc định\n",
    "        finetuned_model = T5ForConditionalGeneration.from_pretrained(base_source).to(device)\n",
    "\n",
    "    # Tokenizer đồng bộ với nguồn model nền (từ local_dir nếu có, hoặc từ tên model)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(base_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea61742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3710' max='3710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3710/3710 4:59:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.084300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.039700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.035600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\" # Tắt Weights & Biases để tránh lỗi khi train trên Kaggle\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"  # giúp giảm phân mảnh VRAM\n",
    "\n",
    "# if to_train:\n",
    "#     # Tạo thư mục output duy nhất với timestamp để lưu kết quả train\n",
    "#     output_dir = f'./sql-training-{str(int(time.time()))}'\n",
    "\n",
    "#     # Cấu hình tham số huấn luyện\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=output_dir, # Thư mục lưu kết quả huấn luyện\n",
    "#         learning_rate=5e-3, # Tốc độ học của mô hình (càng lớn càng nhanh nhưng dễ quá khớp)\n",
    "#         num_train_epochs=1, # Số epoch huấn luyện (có thể tăng lên 2,3,... để cải thiện độ chính xác nhưng tốn thời gian hơn)\n",
    "#         per_device_train_batch_size=8, # Dùng batch size 16 (có thể tăng lên nếu GPU đủ lớn, giúp mô hình học tốt hơn)\n",
    "#         per_device_eval_batch_size=8, # Dùng batch size 16 cho đánh giá\n",
    "#         weight_decay=0.01, # Hệ số weight decay để tránh overfitting (thường chọn 0.01)\n",
    "#         logging_steps=50, # Ghi log mỗi 50 bước\n",
    "#         eval_strategy=\"steps\", # Đánh giá theo số bước để tránh overfitting, thường chọn 'steps' vì dataset nhỏ\n",
    "#         eval_steps=500, # Đánh giá mỗi 500 bước\n",
    "#         fp16=True,                       # bật mixed precision để tiết kiệm VRAM\n",
    "#         gradient_accumulation_steps=2,   # mô phỏng batch lớn bằng cộng dồn gradient\n",
    "#     )\n",
    "\n",
    "#     # Tạo Trainer để huấn luyện mô hình\n",
    "#     trainer = Trainer(\n",
    "#         model=finetuned_model, # Mô hình cần huấn luyện (ở đây là model gốc chưa fine-tune)\n",
    "#         args=training_args, # Tham số huấn luyện đã cấu hình\n",
    "#         train_dataset=tokenized_datasets['train'], # Dữ liệu huấn luyện\n",
    "#         eval_dataset=tokenized_datasets['validation'], # Dữ liệu đánh giá (validation)\n",
    "#     )\n",
    "\n",
    "#     trainer.train() # Bắt đầu huấn luyện mô hình\n",
    "#     print(\"Training completed successfully!\") # In thông báo hoàn thành huấn luyện\n",
    "\n",
    "\n",
    "#    # Lưu checkpoint fine-tuned (thư mục mặc định ở working dir)\n",
    "#     finetuned_model.save_pretrained(\"finetuned_model_2_epoch\") \n",
    "\n",
    "import os, time, torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "finetuned_model.config.use_cache = False  #  tắt cache để tránh giữ tensor lớn\n",
    "finetuned_model.gradient_checkpointing_enable()  #  chia nhỏ graph tính toán\n",
    "\n",
    "if to_train:\n",
    "    output_dir = f\"./sql-training-{int(time.time())}\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir, # Thư mục lưu kết quả huấn luyện\n",
    "        learning_rate=5e-3,# Tốc độ học của mô hình\n",
    "        num_train_epochs=1, # Số epoch huấn luyện\n",
    "        per_device_train_batch_size=4,   # batch size nhỏ để phù hợp với VRAM (huấn luyện)\n",
    "        per_device_eval_batch_size=4, # batch size nhỏ để phù hợp với VRAM (đánh giá)\n",
    "        gradient_accumulation_steps=4,   # cộng dồn gradient để mô phỏng batch size lớn hơn\n",
    "        weight_decay=0.01, # Hệ số weight decay để tránh overfitting (thường chọn 0.01)\n",
    "        logging_steps=50, # Ghi log mỗi 50 bước\n",
    "        eval_strategy=\"no\", # tắt eval trong lúc train cho nhẹ\n",
    "        save_strategy=\"epoch\", # lưu model mỗi epoch\n",
    "        fp16=True, # mix precision để tiết kiệm VRAM\n",
    "        optim=\"adafactor\", # tối ưu hóa Adafactor tiết kiệm bộ nhớ\n",
    "        report_to=\"none\", # tắt Weights & Biases để tránh lỗi trên Kaggle\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=finetuned_model, # Mô hình cần huấn luyện\n",
    "        args=training_args, # Tham số huấn luyện đã cấu hình\n",
    "        data_collator=data_collator, # Hàm collate để padding theo batch\n",
    "        train_dataset=tokenized_datasets[\"train\"], # Dữ liệu huấn luyện\n",
    "    )\n",
    "\n",
    "    # Dọn sạch cache GPU trước khi train\n",
    "    torch.cuda.empty_cache()\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"✅ Training completed successfully!\")\n",
    "    finetuned_model.save_pretrained(\"finetuned_model_2_epoch\")\n",
    "    tokenizer.save_pretrained(\"finetuned_model_2_epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196cf0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/sql_t5_finetuned/tokenizer_config.json',\n",
       " '/kaggle/working/sql_t5_finetuned/special_tokens_map.json',\n",
       " '/kaggle/working/sql_t5_finetuned/spiece.model',\n",
       " '/kaggle/working/sql_t5_finetuned/added_tokens.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dù đã fine-tune hay chưa, vẫn lưu model/tokenizer vào thư mục làm việc của Kaggle để tải về\n",
    "finetuned_model.save_pretrained(\"/kaggle/working/sql_t5_finetuned\") # Lưu model đã fine-tune vào thư mục làm việc của Kaggle\n",
    "tokenizer.save_pretrained(\"/kaggle/working/sql_t5_finetuned\") # Lưu tokenizer vào thư mục làm việc của Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d127ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị model đã fine-tune (hoặc model gốc nếu chưa fine-tune)\n",
    "print(\"Model:\", finetuned_model) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66ae2e6",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 9) KIỂM THỬ MÔ HÌNH ĐÃ FINE-TUNE (ZERO-SHOT TRÊN MẪU)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc90a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Chuẩn bị model đã fine-tune để suy luận\n",
    "finetuned_model.gradient_checkpointing_disable()  # tắt checkpointing khi inference\n",
    "finetuned_model.config.use_cache = True           # bật lại cache cho generate nhanh\n",
    "finetuned_model.eval()\n",
    "finetuned_model.to(device)\n",
    "\n",
    "# (tùy chọn với baseline)\n",
    "original_model.gradient_checkpointing_disable() if hasattr(original_model, \"gradient_checkpointing_disable\") else None\n",
    "try:\n",
    "    original_model.config.use_cache = True\n",
    "except:\n",
    "    pass\n",
    "original_model.eval()\n",
    "original_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      " Tables:\n",
      "CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)\n",
      "\n",
      "Question:\n",
      "On what Date did the Away team essendon play?\n",
      "\n",
      "Answer:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      " SELECT date FROM table_name_11 WHERE away_team = \"essendon\" \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FINE-TUNED MODEL - ZERO SHOT:\n",
      " SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "question = dataset['test'][index]['question']\n",
    "context  = dataset['test'][index]['context']\n",
    "answer   = dataset['test'][index]['answer']\n",
    "\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize 'prompt' (chuỗi được tạo từ context + question) thành tensors PyTorch\n",
    "# - Nguồn dữ liệu: `prompt` (lấy từ dataset['test'][index]['context'] và ['question'])\n",
    "# - Input: prompt (str), tokenizer (T5Tokenizer), device ('cuda' hoặc 'cpu')\n",
    "# - Output: inputs (dict) chứa 'input_ids' và 'attention_mask' dưới dạng torch.Tensor đã được chuyển lên device\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_tokens = finetuned_model.generate( # dùng phương thức generate để sinh text\n",
    "        inputs[\"input_ids\"], # input_ids của prompt đã tokenized\n",
    "        max_new_tokens=200, # Giới hạn tối đa 200 token mới sinh\n",
    "    )\n",
    "\n",
    "output_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True) # Giải mã token thành text, bỏ qua token đặc biệt\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"INPUT PROMPT:\\n\", prompt)\n",
    "print(\"-\"*80)\n",
    "print(\"BASELINE HUMAN ANSWER:\\n\", answer, \"\\n\")\n",
    "print(\"-\"*80)\n",
    "print(\"FINE-TUNED MODEL - ZERO SHOT:\\n\", output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76681d5b",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 10) ĐÁNH GIÁ SƠ BỘ BẰNG ROUGE (SUBSET 25 MẪU)\n",
    "# ==============================\n",
    " Ghi chú: ROUGE đo độ “giống” chuỗi, không phải thước đo chuẩn cho SQL (Exec-Acc), nhưng dùng ở đây như chỉ báo tham khảo nhanh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a209f",
   "metadata": {},
   "source": [
    "\n",
    "Các bước phía dưới sẽ thực hiện đánh giá định lượng mô hình đã fine-tune bằng metric ROUGE trên một tập mẫu nhỏ (25 mẫu) để so sánh chất lượng sinh SQL giữa model gốc và model đã huấn luyện.  \n",
    "Sau đó, hướng dẫn cách sử dụng mô hình đã fine-tune để sinh truy vấn SQL mới (inference), và đóng gói mô hình thành file zip để tiện tải về hoặc triển khai vào ứng dụng thực tế (FastAPI, Flask, .NET...).\n",
    "\n",
    "**Tóm tắt các bước:**\n",
    "1. Đánh giá mô hình bằng ROUGE (so sánh với đáp án chuẩn).\n",
    "2. Sinh truy vấn SQL mới từ mô hình đã fine-tune (inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07636e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human_baseline_answers</th>\n",
       "      <th>original_model_answers</th>\n",
       "      <th>finetuned_model_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT date FROM table_name_11 WHERE away_team...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT date FROM table_name_11 WHERE away_team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT institution FROM table_1974632_1 WHERE ...</td>\n",
       "      <td>Question: state the institution in glenside, p...</td>\n",
       "      <td>SELECT institution FROM table_1974632_1 WHERE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT home_team FROM table_name_4 WHERE away_...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT home_team FROM table_name_4 WHERE away_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT date FROM table_name_49 WHERE home_team...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT date FROM table_name_49 WHERE home_team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT \"Character\" FROM table_79388 WHERE \"Dur...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT \"Character\" FROM table_79388 WHERE \"Yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SELECT clubs FROM table_name_59 WHERE position...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT clubs FROM table_name_59 WHERE position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SELECT record FROM table_name_72 WHERE date = ...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT record FROM table_name_72 WHERE date = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SELECT DISTINCT flight.flight_id FROM airport_...</td>\n",
       "      <td>CREATE TABLE flight_leg ( flight_id int, leg_n...</td>\n",
       "      <td>SELECT DISTINCT flight.flight_id FROM airport_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SELECT season_joined_league FROM table_name_28...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT season_joined_league FROM table_name_28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT loss FROM table_name_48 WHERE date = \"s...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT loss FROM table_name_48 WHERE date = \"s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SELECT MAX(event) FROM table_30060356_3</td>\n",
       "      <td>Question: What is the highest numbered event? ...</td>\n",
       "      <td>SELECT MAX(event) FROM table_30060356_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SELECT position_in_1959_1960 FROM table_name_4...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT position_in_1959_1960 FROM table_name_4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SELECT 1988 FROM table_name_88 WHERE 1987 = \"1r\"</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT 1988 FROM table_name_88 WHERE 1987 = \"1r\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SELECT MAX(year) FROM table_name_7 WHERE winni...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT MAX(year) FROM table_name_7 WHERE winni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SELECT position_in_1959_1960 FROM table_name_1...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT position_in_1959_1960 FROM table_name_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SELECT 1981 FROM table_name_97 WHERE tournamen...</td>\n",
       "      <td>Question: What is the 1981 value at the Tourna...</td>\n",
       "      <td>SELECT 1981 FROM table_name_97 WHERE tournamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SELECT \"Printer\" FROM table_42927 WHERE \"Date ...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT \"Printer\" FROM table_42927 WHERE \"No. s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SELECT season_joined_league FROM table_name_54...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT season_joined_league FROM table_name_54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SELECT name FROM table_name_86 WHERE opened = ...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT name FROM table_name_86 WHERE opened = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SELECT AVG(Reputation) AS \"average_reputation\"...</td>\n",
       "      <td>CREATE TABLE PostLinks ( Id number, PostId num...</td>\n",
       "      <td>SELECT AVG(CASE WHEN a.Score &gt;= 0 THEN 1 ELSE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SELECT country FROM table_name_79 WHERE score ...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT country FROM table_name_79 WHERE score ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SELECT status FROM table_name_89 WHERE opened ...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT status FROM table_name_89 WHERE opened ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SELECT \"Japanese title\" FROM table_51182 WHERE...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT \"Japanese title\" FROM table_51182 WHERE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SELECT SUM(money___) AS £__ FROM table_name_90...</td>\n",
       "      <td>Question</td>\n",
       "      <td>SELECT SUM(money___) AS $__ FROM table_name_90...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SELECT model FROM table_name_16 WHERE status =...</td>\n",
       "      <td>True</td>\n",
       "      <td>SELECT model FROM table_name_16 WHERE status =...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               human_baseline_answers  \\\n",
       "0   SELECT date FROM table_name_11 WHERE away_team...   \n",
       "1   SELECT institution FROM table_1974632_1 WHERE ...   \n",
       "2   SELECT home_team FROM table_name_4 WHERE away_...   \n",
       "3   SELECT date FROM table_name_49 WHERE home_team...   \n",
       "4   SELECT \"Character\" FROM table_79388 WHERE \"Dur...   \n",
       "5   SELECT clubs FROM table_name_59 WHERE position...   \n",
       "6   SELECT record FROM table_name_72 WHERE date = ...   \n",
       "7   SELECT DISTINCT flight.flight_id FROM airport_...   \n",
       "8   SELECT season_joined_league FROM table_name_28...   \n",
       "9   SELECT loss FROM table_name_48 WHERE date = \"s...   \n",
       "10            SELECT MAX(event) FROM table_30060356_3   \n",
       "11  SELECT position_in_1959_1960 FROM table_name_4...   \n",
       "12   SELECT 1988 FROM table_name_88 WHERE 1987 = \"1r\"   \n",
       "13  SELECT MAX(year) FROM table_name_7 WHERE winni...   \n",
       "14  SELECT position_in_1959_1960 FROM table_name_1...   \n",
       "15  SELECT 1981 FROM table_name_97 WHERE tournamen...   \n",
       "16  SELECT \"Printer\" FROM table_42927 WHERE \"Date ...   \n",
       "17  SELECT season_joined_league FROM table_name_54...   \n",
       "18  SELECT name FROM table_name_86 WHERE opened = ...   \n",
       "19  SELECT AVG(Reputation) AS \"average_reputation\"...   \n",
       "20  SELECT country FROM table_name_79 WHERE score ...   \n",
       "21  SELECT status FROM table_name_89 WHERE opened ...   \n",
       "22  SELECT \"Japanese title\" FROM table_51182 WHERE...   \n",
       "23  SELECT SUM(money___) AS £__ FROM table_name_90...   \n",
       "24  SELECT model FROM table_name_16 WHERE status =...   \n",
       "\n",
       "                               original_model_answers  \\\n",
       "0                                            Question   \n",
       "1   Question: state the institution in glenside, p...   \n",
       "2                                                True   \n",
       "3                                            Question   \n",
       "4                                                True   \n",
       "5                                            Question   \n",
       "6                                            Question   \n",
       "7   CREATE TABLE flight_leg ( flight_id int, leg_n...   \n",
       "8                                            Question   \n",
       "9                                                True   \n",
       "10  Question: What is the highest numbered event? ...   \n",
       "11                                               True   \n",
       "12                                           Question   \n",
       "13                                               True   \n",
       "14                                               True   \n",
       "15  Question: What is the 1981 value at the Tourna...   \n",
       "16                                               True   \n",
       "17                                               True   \n",
       "18                                               True   \n",
       "19  CREATE TABLE PostLinks ( Id number, PostId num...   \n",
       "20                                           Question   \n",
       "21                                               True   \n",
       "22                                               True   \n",
       "23                                           Question   \n",
       "24                                               True   \n",
       "\n",
       "                              finetuned_model_answers  \n",
       "0   SELECT date FROM table_name_11 WHERE away_team...  \n",
       "1   SELECT institution FROM table_1974632_1 WHERE ...  \n",
       "2   SELECT home_team FROM table_name_4 WHERE away_...  \n",
       "3   SELECT date FROM table_name_49 WHERE home_team...  \n",
       "4   SELECT \"Character\" FROM table_79388 WHERE \"Yea...  \n",
       "5   SELECT clubs FROM table_name_59 WHERE position...  \n",
       "6   SELECT record FROM table_name_72 WHERE date = ...  \n",
       "7   SELECT DISTINCT flight.flight_id FROM airport_...  \n",
       "8   SELECT season_joined_league FROM table_name_28...  \n",
       "9   SELECT loss FROM table_name_48 WHERE date = \"s...  \n",
       "10            SELECT MAX(event) FROM table_30060356_3  \n",
       "11  SELECT position_in_1959_1960 FROM table_name_4...  \n",
       "12   SELECT 1988 FROM table_name_88 WHERE 1987 = \"1r\"  \n",
       "13  SELECT MAX(year) FROM table_name_7 WHERE winni...  \n",
       "14  SELECT position_in_1959_1960 FROM table_name_1...  \n",
       "15  SELECT 1981 FROM table_name_97 WHERE tournamen...  \n",
       "16  SELECT \"Printer\" FROM table_42927 WHERE \"No. s...  \n",
       "17  SELECT season_joined_league FROM table_name_54...  \n",
       "18  SELECT name FROM table_name_86 WHERE opened = ...  \n",
       "19  SELECT AVG(CASE WHEN a.Score >= 0 THEN 1 ELSE ...  \n",
       "20  SELECT country FROM table_name_79 WHERE score ...  \n",
       "21  SELECT status FROM table_name_89 WHERE opened ...  \n",
       "22  SELECT \"Japanese title\" FROM table_51182 WHERE...  \n",
       "23  SELECT SUM(money___) AS $__ FROM table_name_90...  \n",
       "24  SELECT model FROM table_name_16 WHERE status =...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "import pandas as pd\n",
    "\n",
    "questions = dataset['test'][0:25]['question']\n",
    "contexts  = dataset['test'][0:25]['context']\n",
    "human_baseline_answers = dataset['test'][0:25]['answer']\n",
    "\n",
    "original_model_answers  = []\n",
    "finetuned_model_answers = []\n",
    "\n",
    "gen_cfg = GenerationConfig(max_new_tokens=300)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for q, c in zip(questions, contexts):\n",
    "        prompt = f\"\"\"Tables:\n",
    "{c}\n",
    "\n",
    "Question:\n",
    "{q}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "        # Baseline\n",
    "        out_base = original_model.generate(input_ids=input_ids, generation_config=gen_cfg)\n",
    "        original_model_answers.append(tokenizer.decode(out_base[0], skip_special_tokens=True))\n",
    "\n",
    "        # Fine-tuned\n",
    "        out_ft = finetuned_model.generate(input_ids=input_ids, generation_config=gen_cfg)\n",
    "        finetuned_model_answers.append(tokenizer.decode(out_ft[0], skip_special_tokens=True))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    zip(human_baseline_answers, original_model_answers, finetuned_model_answers),\n",
    "    columns=[\"human_baseline_answers\", \"original_model_answers\", \"finetuned_model_answers\"]\n",
    ")\n",
    "\n",
    "display(df)  # nếu muốn xem bảng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3a9ae77b989177786d9963eaa176845032325aa644956df0df7a0c39f1389271\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73d0fd",
   "metadata": {},
   "source": [
    "Compute ROUGE score for this subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521f7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c731cf10145d4cefbf985fa0bd5524fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.031233998975934457, 'rouge2': 0.005, 'rougeL': 0.03151917519331407, 'rougeLsum': 0.03174603174603174}\n",
      "FINE-TUNED MODEL:\n",
      "{'rouge1': 0.9265132150912692, 'rouge2': 0.903794543074439, 'rougeL': 0.921148312345613, 'rougeLsum': 0.9178219960064249}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge') # Nạp metric ROUGE từ thư viện evaluate\n",
    "\n",
    "original_model_results = rouge.compute( # Tính toán ROUGE cho model gốc\n",
    "    predictions=original_model_answers, # Dự đoán từ model gốc\n",
    "    references=human_baseline_answers[0:len(original_model_answers)], # Đáp án chuẩn tương ứng\n",
    "    use_aggregator=True, # Sử dụng hàm tổng hợp kết quả\n",
    "    use_stemmer=True, # Sử dụng stemming để cải thiện so khớp\n",
    ")\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results) # In kết quả ROUGE cho model gốc\n",
    "\n",
    "\n",
    "finetuned_model_results = rouge.compute( # Tính toán ROUGE cho model đã fine-tune\n",
    "    predictions=finetuned_model_answers, # Dự đoán từ model đã fine-tune\n",
    "    references=human_baseline_answers[0:len(finetuned_model_answers)], # Đáp án chuẩn tương ứng\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('FINE-TUNED MODEL:')\n",
    "print(finetuned_model_results) # In kết quả ROUGE cho model đã fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df681e",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 11) HÀM SUY LUẬN (INFERENCE) VỚI MÔ HÌNH ĐÃ FINE-TUNE\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query:\n",
      "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer # Model và Tokenizer T5 (nạp lại để chắc chắn)\n",
    "import torch\n",
    "\n",
    "# Nạp mô hình đã fine-tune và tokenizer từ thư mục lưu trên Kaggle\n",
    "model_path = \"sql_t5_finetuned\" # Thư mục ngay dưới /kaggle/working\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to('cuda')\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Hàm tiện ích để sinh truy vấn SQL từ context và question\n",
    "def generate_sql(context, question):\n",
    "    prompt = f\"\"\"Tables:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=200,\n",
    "        )[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "# Ví dụ inference với một mẫu từ tập test (phần tử đầu tiên)\n",
    "index = 0\n",
    "context = dataset['test'][index]['context']\n",
    "question = dataset['test'][index]['question']\n",
    "\n",
    "output = generate_sql(context, question)\n",
    "\n",
    "print(f\"Generated SQL Query:\\n{output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4aef8",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 12) ĐÓNG GÓI MÔ HÌNH ĐỂ TẢI XUỐNG\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cài thêm để chạy service nếu cần (không bắt buộc)\n",
    "!pip install fastapi uvicorn transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd30c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/sql_t5_finetuned.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil # Thư viện shutil để nén file zip\n",
    "\n",
    "# Nén thư mục model đã fine-tune để tiện download từ Kaggle\n",
    "shutil.make_archive(\n",
    "    '/kaggle/working/sql_t5_finetuned',  # tên file zip đầu ra\n",
    "    'zip',                               # định dạng nén\n",
    "    '/kaggle/working/finetuned_model_2_epoch'  # thư mục model thật sự\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f968a22",
   "metadata": {},
   "source": [
    "**Nén toàn bộ dữ liệu quan trọng gồm model, dataset gốc, tokenized dataset, checkpoint training — để tải 1 lần duy nhất.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2e84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã nén toàn bộ dữ liệu thành công!\n",
      " File nén nằm tại: /kaggle/working/olms_sql_full_backup.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Đường dẫn thư mục làm việc\n",
    "base_dir = \"/kaggle/working\"\n",
    "\n",
    "# Đường dẫn file zip đầu ra\n",
    "output_zip = f\"{base_dir}/olms_sql_full_backup\"\n",
    "\n",
    "# Nén toàn bộ working directory (model + dataset + checkpoint)\n",
    "shutil.make_archive(output_zip, 'zip', base_dir)\n",
    "\n",
    "print(\"Đã nén toàn bộ dữ liệu thành công!\")\n",
    "print(f\" File nén nằm tại: {output_zip}.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
