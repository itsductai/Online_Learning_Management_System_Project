{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15af3922",
   "metadata": {},
   "source": [
    "# =============================================\n",
    "## GHI CHÚ TỔNG QUAN (NOTE – DÀNH CHO KAGGLE)\n",
    "# =============================================\n",
    " **Mục tiêu**\n",
    " - Fine-tune mô hình T5 (seq2seq) cho bài toán Text-to-SQL trên Kaggle.\n",
    " - Dùng dataset công khai (b-mc2/sql-create-context, Clinton/Text-to-sql-v1, knowrohit07/know_sql),\n",
    " sau đó trộn, tiền xử lý (tokenize), huấn luyện, lưu mô hình.\n",
    " - Không thay đổi logic cốt lõi; chỉ bổ sung chú thích chi tiết.\n",
    "\n",
    " **Luồng chính**\n",
    " 1) Cài đặt thư viện → Import.\n",
    " 2) Nạp/ghép dataset có sẵn → lưu cache (merged_dataset).\n",
    " 3) Tiền xử lý (tokenize) → lưu cache (tokenized_datasets).\n",
    " 4) Kiểm thử zero-shot (baseline) trên model gốc.\n",
    " 5) Huấn luyện full fine-tune → lưu mô hình đã fine-tune.\n",
    " 6) Kiểm thử lại với mô hình fine-tuned + đánh giá (ROUGE) mẫu nhỏ.\n",
    " 7) Đóng gói mô hình (zip) để tải xuống / dùng về sau.\n",
    "\n",
    " **Đầu ra (sản phẩm)**\n",
    " - Thư mục model đã fine-tune: /kaggle/working/sql_t5_finetuned\n",
    " - Có thể nạp về app (FastAPI/Flask/.NET-bridge) bằng from_pretrained(\"/kaggle/working/sql_t5_finetuned\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57878da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (3.8)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện datasets nếu chưa có\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21d77d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (0.35.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from evaluate) (24.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt thư viện evaluate\n",
    "!pip install evaluate \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6dec79",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 2) IMPORT CÁC THƯ VIỆN CẦN THIẾT\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5783435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.20.0Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Uninstalling tensorflow-2.20.0:\n",
      "  Successfully uninstalled tensorflow-2.20.0\n",
      "Found existing installation: tensorflow-intel 2.17.0\n",
      "Uninstalling tensorflow-intel-2.17.0:\n",
      "  Successfully uninstalled tensorflow-intel-2.17.0\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y tensorflow tensorflow-intel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f533fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cpu\n",
      "Uninstalling torch-2.6.0+cpu:\n",
      "  Successfully uninstalled torch-2.6.0+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~~rch'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6892f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (74.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp312-cp312-win_amd64.whl (109.2 MB)\n",
      "   ---------------------------------------- 0.0/109.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/109.2 MB 6.3 MB/s eta 0:00:18\n",
      "    --------------------------------------- 2.4/109.2 MB 6.4 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 3.7/109.2 MB 6.2 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 4.7/109.2 MB 5.9 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 6.0/109.2 MB 6.0 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 7.1/109.2 MB 6.0 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 8.4/109.2 MB 6.0 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 9.7/109.2 MB 6.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 11.0/109.2 MB 6.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.1/109.2 MB 6.0 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 13.4/109.2 MB 5.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 14.4/109.2 MB 5.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 15.5/109.2 MB 5.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 16.8/109.2 MB 5.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 18.1/109.2 MB 5.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 19.1/109.2 MB 5.8 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 20.4/109.2 MB 5.9 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 21.5/109.2 MB 5.8 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 22.5/109.2 MB 5.8 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 24.1/109.2 MB 5.8 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 25.4/109.2 MB 5.8 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 26.5/109.2 MB 5.8 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 27.5/109.2 MB 5.8 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 28.8/109.2 MB 5.8 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 30.1/109.2 MB 5.8 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 31.5/109.2 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 32.8/109.2 MB 5.9 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 34.1/109.2 MB 5.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 35.4/109.2 MB 5.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 36.4/109.2 MB 5.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 37.7/109.2 MB 5.9 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 39.1/109.2 MB 5.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 40.4/109.2 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 41.4/109.2 MB 5.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 42.7/109.2 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 44.0/109.2 MB 5.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 45.4/109.2 MB 5.9 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 46.4/109.2 MB 5.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 47.4/109.2 MB 5.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 48.8/109.2 MB 5.8 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 49.8/109.2 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 51.1/109.2 MB 5.8 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 52.4/109.2 MB 5.8 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 53.5/109.2 MB 5.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 54.8/109.2 MB 5.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 56.1/109.2 MB 5.8 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 57.1/109.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 58.5/109.2 MB 5.8 MB/s eta 0:00:09\n",
      "   --------------------- ------------------ 59.8/109.2 MB 5.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 60.8/109.2 MB 5.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 61.1/109.2 MB 5.8 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 61.6/109.2 MB 5.7 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 62.7/109.2 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 64.0/109.2 MB 5.7 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 65.0/109.2 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 66.1/109.2 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------ --------------- 67.1/109.2 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 68.4/109.2 MB 5.7 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 69.7/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   ------------------------- -------------- 70.5/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 71.8/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 72.9/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   -------------------------- ------------- 73.7/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 74.7/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 75.8/109.2 MB 5.6 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 76.8/109.2 MB 5.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 77.9/109.2 MB 5.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ----------- 79.2/109.2 MB 5.6 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 80.2/109.2 MB 5.6 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 81.3/109.2 MB 5.6 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 82.3/109.2 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 83.4/109.2 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------ --------- 84.4/109.2 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 85.5/109.2 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 86.8/109.2 MB 5.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 87.8/109.2 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 88.9/109.2 MB 5.5 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 89.9/109.2 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 91.0/109.2 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 92.3/109.2 MB 5.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 93.3/109.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 94.6/109.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 95.7/109.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 96.7/109.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 98.0/109.2 MB 5.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 99.1/109.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 100.1/109.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 101.4/109.2 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 102.5/109.2 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 103.8/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 104.9/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 105.9/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.2/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.3/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.2/109.2 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 8.5 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.3/4.3 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 2.4/4.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.4/4.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp312-cp312-win_amd64.whl (663 kB)\n",
      "   ---------------------------------------- 0.0/663.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 663.1/663.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.3 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.4/6.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "Successfully installed sympy-1.14.0 torch-2.9.0+cpu torchaudio-2.9.0+cpu torchvision-0.24.0+cpu\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e827f906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu False\n"
     ]
    }
   ],
   "source": [
    "import torch; \n",
    "print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0734bc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, load_dataset, interleave_datasets, load_from_disk # Dataset Huggingface\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer # Model và Tokenizer cho trainning\n",
    "import torch # Thư viện PyTorch tăng tốc độ xử lý GPU, tensor\n",
    "import time # Ghi thời gian trainning\n",
    "import evaluate # Thư viện evaluate để đánh giá mô hình (BLEU, ROUGE)\n",
    "import pandas as pd # Thư viện pandas để xử lý dữ liệu dạng bảng/kết quả\n",
    "import numpy as np # Thư viện numpy để xử lý mảng\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Bỏ qua các cảnh báo không cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8a027e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.57.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers) (2024.7.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Import thư viện transformers và huggingface_hub\n",
    "!pip install transformers huggingface_hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9de8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer # Model và Tokenizer T5\n",
    "\n",
    "import os # Thư viện os để thao tác với hệ thống tệp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a3a12",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 3) CẤU HÌNH ĐƯỜNG DẪN VÀ THIẾT BỊ\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c21850",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_model_path = '/kaggle/working/' # Đường dẫn lưu model trên Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd1fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # Kiểm tra GPU có sẵn không, trả về True hoặc False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24ae660",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='t5-small' # Tên model nền; code gốc chọn t5-small cho baseline/finetune\n",
    "\n",
    "# Tạo tokenizer từ model nền\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "\n",
    "# Nạp model gốc (baseline) để so sánh trước/sau fine-tune\n",
    "# Dùng dtype bfloat16 cho hiệu năng; chuyển model sang GPU nếu có\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "original_model = original_model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a80e35",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 4) NẠP/CHUẨN BỊ DATASET (CÓ CACHE)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f963f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249a8890feee443889d696e138023f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60afc07bb72846b5bc045dbacf9a3d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sql_create_context_v4.json:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a38ab8af8743489e6a4e0fa979fc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/78577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352cc17e07ec40f7b84ef7631dffc0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/118 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fc33d33d3c4f87a883807f5698ac10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "texttosqlv2.jsonl:   0%|          | 0.00/635M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9232dd8681c9496ca4bdda454b911f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/262208 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c608c8f01d3464eb25fd4b5ca9c8548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb0f316c7e34e1583f849c653b97ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "know_sql_val3%7Bign%7D.json:   0%|          | 0.00/13.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb09b81f854b8aaa1b429b05f75c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/49456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102a717ada30481f8d418922d4de557f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/118695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e86da2378b4a4f9dbbffa68b063771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633d90378155427994bf1c5526206fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged and Saved Dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 118695\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 14835\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 14838\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cố gắng nạp dataset đã merge sẵn từ cache \"merged_dataset\" để tiết kiệm thời gian\n",
    "try:\n",
    "    dataset = load_from_disk(\"merged_dataset\")\n",
    "    print(\"Loaded Merged Dataset\")\n",
    "except:\n",
    "    # Nếu không có cache, tiến hành tải và merge 3 dataset công khai và chia split thủ công\n",
    "    \n",
    "    # 4.1) b-mc2/sql-create-context (chứa question/context/answer)\n",
    "    dataset_scc_train = load_dataset(\"b-mc2/sql-create-context\", split='train[:80%]') # 80% train\n",
    "    dataset_scc_test  = load_dataset(\"b-mc2/sql-create-context\", split='train[-20%:-10%]') # 10% test\n",
    "    dataset_scc_val   = load_dataset(\"b-mc2/sql-create-context\", split='train[-10%:]') # 10% validation\n",
    "\n",
    "    # 4.2) Clinton/Text-to-sql-v1 (đổi tên cột để thống nhất question/context/answer)\n",
    "\n",
    "    dataset_tts_train = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[:80%]') # 80% train\n",
    "    dataset_tts_train = dataset_tts_train.remove_columns(['source', 'text']) # Bỏ cột không cần thiết\n",
    "    dataset_tts_train = dataset_tts_train.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'}) # Đổi tên cột cho thống nhất với dataset_scc\n",
    "    \n",
    "    dataset_tts_test  = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-20%:-10%]') # 10% test\n",
    "    dataset_tts_test  = dataset_tts_test.remove_columns(['source', 'text']) \n",
    "    dataset_tts_test  = dataset_tts_test.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'}) \n",
    "    dataset_tts_val   = load_dataset(\"Clinton/Text-to-sql-v1\", split='train[-10%:]') # 10% validation\n",
    "    dataset_tts_val   = dataset_tts_val.remove_columns(['source', 'text'])\n",
    "    dataset_tts_val   = dataset_tts_val.rename_columns({'instruction': 'question', 'input': 'context', 'response': 'answer'})\n",
    "\n",
    "    # 4.3) knowrohit07/know_sql (đổi tên cột để thống nhất question/context/answer)\n",
    "    dataset_ks_train  = load_dataset(\"knowrohit07/know_sql\", split='validation[:80%]')\n",
    "    dataset_ks_test   = load_dataset(\"knowrohit07/know_sql\", split='validation[-20%:-10%]')\n",
    "    dataset_ks_val    = load_dataset(\"knowrohit07/know_sql\", split='validation[-10%:]')\n",
    "\n",
    "    # 4.4) Ghép 3 nguồn lại bằng interleave_datasets để tăng đa dạng dữ liệu\n",
    "    dataset = DatasetDict({ 'train': interleave_datasets([dataset_scc_train, dataset_tts_train, dataset_ks_train]),\n",
    "                            'test': interleave_datasets([dataset_scc_test, dataset_tts_test, dataset_ks_test]),\n",
    "                            'validation': interleave_datasets([dataset_scc_val, dataset_tts_val, dataset_ks_val])})\n",
    "\n",
    "    # Lưu dataset đã merge vào cache \"merged_dataset\" để lần sau dùng lại\n",
    "    dataset.save_to_disk(\"merged_dataset\")\n",
    "    print(\"Merged and Saved Dataset\")\n",
    "\n",
    "dataset # Hiển thị thông tin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2250ae17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'SELECT date FROM table_name_11 WHERE away_team = \"essendon\"',\n",
       " 'question': 'On what Date did the Away team essendon play?',\n",
       " 'context': 'CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset['test'][0] # Kiểm tra một mẫu trong tập test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28780f4",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 5) HÀM TIỀN XỬ LÝ (TOKENIZE) + TẠO PROMPT\n",
    "# ==============================\n",
    "\n",
    "Ở bước này, cần chuyển đổi các bộ dữ liệu thành dạng hướng dẫn rõ ràng cho mô hình ngôn ngữ lớn (LLM).\n",
    "\n",
    "Sau đó, tiến hành tiền xử lý dữ liệu prompt-response bằng cách mã hóa (tokenize) để lấy ra các input_ids phục vụ cho quá trình huấn luyện.\n",
    "\n",
    "Ghi chú: Chuyển dữ liệu dạng (context/question/answer) → (input_ids/labels) cho T5\n",
    " Prompt dạng:\n",
    " Tables:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9d7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13931868842446a99aeabe954fc9c0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/118695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634095ec05054eaabfdbb982d61bfbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c08165fea244aca3529bbe90dcefd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d0facdee0648f795d01a4471300b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/118695 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d71d267bd16432ca883208677c41d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14835 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9262bf6d81b2420587be91c55771541b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized and Saved Dataset\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example): # Hàm tokenize_function để tiền xử lý dữ liệu\n",
    "\n",
    "#     print(len(example[\"question\"]))\n",
    "# # Tiền tố/giữa/hậu cho prompt để mô hình rõ cấu trúc đầu vào\n",
    "    start_prompt = \"Tables:\\n\" # Bắt đầu với Tables:\n",
    "    middle_prompt = \"\\n\\nQuestion:\\n\" # Giữa là Question:\n",
    "    end_prompt = \"\\n\\nAnswer:\\n\" # Kết thúc với Answer:\n",
    "\n",
    "    # Ghép promt theo từng cặp context/question\n",
    "    data_zip = zip(example['context'], example['question']) # Ghép cặp context và question\n",
    "    prompt = [start_prompt + context + middle_prompt + question + end_prompt for context, question in data_zip] # Tạo prompt hoàn chỉnh\n",
    "    \n",
    "    # Mã hoá prompt → input_ids (padding/truncation theo mặc định max_length của tokenizer)\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids # Tokenize prompt\n",
    "    \n",
    "    # Mã hoá câu trả lời (answer) → labels\n",
    "    example['labels'] = tokenizer(example['answer'], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids # Tokenize answer\n",
    "#     print(prompt[0])\n",
    "#     print()\n",
    "\n",
    "    return example\n",
    "\n",
    "# Ghi chú: Hàm trên sẽ được áp vào cả 3 split (train/validation/test) bằng map(batched=True)\n",
    "# batched=True để xử lý theo lô, tăng tốc độ xử lý\n",
    "# Hàm tokenize_function xử lý tất cả dữ liệu trên tất cả các split theo lô.\n",
    "\n",
    "\n",
    "# Cố gắng nạp dataset đã tokenized sẵn từ cache \"tokenized_datasets\" để tiết kiệm thời gian\n",
    "try:\n",
    "    # Thử nạp từ cache nếu đã tokenized trước đó\n",
    "    tokenized_datasets = load_from_disk(\"tokenized_datasets\") \n",
    "    print(\"Loaded Tokenized Dataset\")\n",
    "except:\n",
    "    # Nếu chưa có cache, thực thi map → loại bỏ cột thừa → lưu cache\n",
    "    tokenized_datasets = dataset.map(tokenize_function, batched=True) # Áp dụng hàm tokenize_function cho toàn bộ dataset\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(['question', 'context', 'answer']) # Loại bỏ cột thừa để tiết kiệm bộ nhớ\n",
    "\n",
    "    # Lưu dataset đã tokenized vào cache \"tokenized_datasets\" để lần sau dùng lại\n",
    "    tokenized_datasets.save_to_disk(\"tokenized_datasets\")\n",
    "    print(\"Tokenized and Saved Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'test', 'validation'])\n",
      "dict_keys(['input_ids', 'labels'])\n",
      "[4398, 7, 10, 205, 4386, 6048, 332, 17098, 819, 41]\n",
      "[3, 23143, 14196, 2847, 17161, 599, 1935, 61, 21680, 819]\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 118695\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14838\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị thông tin tokenized_datasets kiểm tra nhanh khóa/cấu trúc trước khi train\n",
    "print(tokenized_datasets.keys()) # Hiển thị các split có trong tokenized_datasets\n",
    "print(tokenized_datasets['train'][0].keys()) # Hiển thị các khóa trong một mẫu của tập train\n",
    "print(tokenized_datasets['train'][0]['input_ids'][:10]) # Hiển thị 10 token đầu tiên của input_ids\n",
    "print(tokenized_datasets['train'][0]['labels'][:10]) # Hiển thị 10 token đầu tiên của labels\n",
    "print(tokenized_datasets) # Hiển thị thông tin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (118695, 2)\n",
      "Validation: (14838, 2)\n",
      "Test: (14835, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 118695\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 14838\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\") # In kích thước tập train (số mẫu, số cột)\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\") # In kích thước tập validation (số mẫu, số cột)\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\") # In kích thước tập test (số mẫu, số cột)\n",
    "\n",
    "print(tokenized_datasets) # Hiển thị thông tin tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d7863",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 7) KIỂM THỬ ZERO-SHOT VỚI MODEL GỐC (BASELINE)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Your input prompt here\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "Expected human response here\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "Votre prompt here\n"
     ]
    }
   ],
   "source": [
    "import torch # Thư viện PyTorch tăng tốc độ xử lý GPU, tensor\n",
    "\n",
    "# Định nghĩa prompt & answer mẫu để test nhanh (người dùng cần thay bằng ví dụ thật)\n",
    "prompt = \"Your input prompt here\"  # Ví dụ: Tables + Question (cần thay bằng prompt thực)\n",
    "answer = \"Expected human response here\"  # Ví dụ: câu SQL chuẩn tương ứng (đáp án chuẩn)\n",
    "\n",
    "# Đảm bảo model và input cùng trên một thiết bị (CPU hoặc GPU) nếu có\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Di chuyển model sang thiết bị phù hợp (device = CPU hoặc GPU)\n",
    "original_model.to(device)\n",
    "\n",
    "# Tokenize đầu vào input và chuyển nó sang cùng thiết bị với model\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "# Sinh đầu ra zero-shot từ model gốc (chưa fine-tune)\n",
    "output = tokenizer.decode( # dùng tokenizer.decode để giải mã token thành text\n",
    "    original_model.generate( # dùng phương thức generate để sinh text\n",
    "        inputs[\"input_ids\"], # input_ids của prompt đã tokenized\n",
    "        max_new_tokens=200, # Giới hạn tối đa 200 token mới sinh\n",
    "    )[0], # Lấy mảng token đầu tiên trong batch (ở đây batch size=1)\n",
    "    skip_special_tokens=True # Bỏ qua các token đặc biệt khi giải mã\n",
    ")\n",
    "\n",
    "# In kết quả zero-shot baseline\n",
    "dash_line = '-' * 100 \n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}') \n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6269f",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 8) HUẤN LUYỆN FULL FINE-TUNE (KAGGLE GPU)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77d5c9d",
   "metadata": {},
   "source": [
    "#### 5e-3\n",
    "\n",
    "Thời gian huấn luyện      = 2 giờ 49 phút 1 giây trên laptop sử dụng notebook Kaggle (PC cá nhân không đủ bộ nhớ CUDA để huấn luyện với tập dữ liệu lớn)\n",
    "\n",
    "Training Loss   = 0.023100\n",
    "\n",
    "Validation Loss = 0.013285\n",
    "\n",
    "---\n",
    "\n",
    "**Giải thích:**\n",
    "\n",
    "- **5e-3**: Đây là giá trị learning rate (tốc độ học) được sử dụng khi huấn luyện mô hình. Giá trị này ảnh hưởng đến tốc độ cập nhật trọng số của mô hình trong quá trình học.\n",
    "- **Thời gian huấn luyện**: Tổng thời gian để hoàn thành quá trình fine-tune mô hình trên GPU của Kaggle. Nếu dùng máy cá nhân (PC) không có đủ bộ nhớ CUDA thì sẽ không thể huấn luyện với tập dữ liệu lớn.\n",
    "- **Training Loss**: Độ lỗi (loss) trên tập huấn luyện. Giá trị càng nhỏ chứng tỏ mô hình học tốt trên dữ liệu huấn luyện.\n",
    "- **Validation Loss**: Độ lỗi trên tập kiểm thử (validation). Giá trị này dùng để đánh giá khả năng tổng quát hóa của mô hình trên dữ liệu chưa từng thấy. Nếu validation loss thấp và gần với training loss, mô hình không bị overfit.\n",
    "\n",
    "**Kết luận:**  \n",
    "Mô hình đã được huấn luyện với tốc độ học 5e-3, thời gian gần 3 tiếng trên GPU của Kaggle. Kết quả training loss và validation loss đều thấp, chứng tỏ mô hình học tốt và có khả năng tổng quát hóa tốt trên dữ liệu kiểm thử."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cố gắng nạp model đã fine-tune từ \"finetuned_model_2_epoch\" nếu có\n",
    "try:\n",
    "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"finetuned_model_2_epoch\") # Nạp model đã fine-tune nếu có\n",
    "    finetuned_model = finetuned_model.to('cuda') # Chuyển model sang GPU nếu có\n",
    "    to_train = False # Nếu có model fine-tune, không cần train lại\n",
    "\n",
    "except:\n",
    "    # Nếu không có model fine-tune, nạp model gốc để fine-tune\n",
    "    to_train = True # Nếu không có model fine-tune, sẽ tiến hành fine-tune\n",
    "    finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16) # Nạp model gốc với dtype bfloat16\n",
    "    #finetuned_model = finetuned_model.to('cuda')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name) # Nạp lại tokenizer từ model nền"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c53a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7419' max='7419' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7419/7419 2:51:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.042019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>0.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.025905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.022786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.020304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.017546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.016787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.016067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.015377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.014977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.014771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.014634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.014581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n",
      "CPU times: user 2h 24min 29s, sys: 27min 16s, total: 2h 51min 46s\n",
      "Wall time: 2h 51min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time # Đo thời gian chạy cell này trên Kaggle \n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" # Tắt Weights & Biases để tránh lỗi khi train trên Kaggle\n",
    "\n",
    "if to_train:\n",
    "    # Tạo thư mục output duy nhất với timestamp để lưu kết quả train\n",
    "    output_dir = f'./sql-training-{str(int(time.time()))}'\n",
    "\n",
    "    # Cấu hình tham số huấn luyện\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir, # Thư mục lưu kết quả huấn luyện\n",
    "        learning_rate=5e-3, # Tốc độ học của mô hình (càng lớn càng nhanh nhưng dễ quá khớp)\n",
    "        num_train_epochs=1, # Số epoch huấn luyện (có thể tăng lên 2,3,... để cải thiện độ chính xác nhưng tốn thời gian hơn)\n",
    "        per_device_train_batch_size=16, # Dùng batch size 16 (có thể tăng lên nếu GPU đủ lớn, giúp mô hình học tốt hơn)\n",
    "        per_device_eval_batch_size=16, # Dùng batch size 16 cho đánh giá\n",
    "        weight_decay=0.01, # Hệ số weight decay để tránh overfitting (thường chọn 0.01)\n",
    "        logging_steps=50, # Ghi log mỗi 50 bước\n",
    "        evaluation_strategy='steps', # Đánh giá theo số bước để tránh overfitting, thường chọn 'steps' vì dataset nhỏ\n",
    "        eval_steps=500, # Đánh giá mỗi 500 bước\n",
    "    )\n",
    "\n",
    "    # Tạo Trainer để huấn luyện mô hình\n",
    "    trainer = Trainer(\n",
    "        model=finetuned_model, # Mô hình cần huấn luyện (ở đây là model gốc chưa fine-tune)\n",
    "        args=training_args, # Tham số huấn luyện đã cấu hình\n",
    "        train_dataset=tokenized_datasets['train'], # Dữ liệu huấn luyện\n",
    "        eval_dataset=tokenized_datasets['validation'], # Dữ liệu đánh giá (validation)\n",
    "    )\n",
    "\n",
    "    trainer.train() # Bắt đầu huấn luyện mô hình\n",
    "    print(\"Training completed successfully!\") # In thông báo hoàn thành huấn luyện\n",
    "\n",
    "\n",
    "   # Lưu checkpoint fine-tuned (thư mục mặc định ở working dir)\n",
    "    finetuned_model.save_pretrained(\"finetuned_model_2_epoch\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b1407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/sql_t5_finetuned/tokenizer_config.json',\n",
       " '/kaggle/working/sql_t5_finetuned/special_tokens_map.json',\n",
       " '/kaggle/working/sql_t5_finetuned/spiece.model',\n",
       " '/kaggle/working/sql_t5_finetuned/added_tokens.json',\n",
       " '/kaggle/working/sql_t5_finetuned/tokenizer.json')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dù đã fine-tune hay chưa, vẫn lưu model/tokenizer vào thư mục làm việc của Kaggle để tải về\n",
    "finetuned_model.save_pretrained(\"/kaggle/working/sql_t5_finetuned\") # Lưu model đã fine-tune vào thư mục làm việc của Kaggle\n",
    "tokenizer.save_pretrained(\"/kaggle/working/sql_t5_finetuned\") # Lưu tokenizer vào thư mục làm việc của Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bede6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 8)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
      "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseActDense(\n",
      "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
      "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): ReLU()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị model đã fine-tune (hoặc model gốc nếu chưa fine-tune)\n",
    "print(\"Model:\", finetuned_model) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2140ade",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 9) KIỂM THỬ MÔ HÌNH ĐÃ FINE-TUNE (ZERO-SHOT TRÊN MẪU)\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba9ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "Tables:\n",
      "CREATE TABLE table_name_11 (date VARCHAR, away_team VARCHAR)\n",
      "\n",
      "Question:\n",
      "On what Date did the Away team essendon play?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN ANSWER:\n",
      "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "FINE-TUNED MODEL - ZERO SHOT:\n",
      "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n"
     ]
    }
   ],
   "source": [
    "index = 0 # Thay đổi index để kiểm tra các mẫu khác nhau trong tập test (lấy mẫu đầu tiên để minh họa)\n",
    "# index = len(dataset['test'])-200\n",
    "\n",
    "question = dataset['test'][index]['question'] # Lấy câu hỏi từ tập test\n",
    "context = dataset['test'][index]['context'] # Lấy context từ tập test\n",
    "answer = dataset['test'][index]['answer'] # Lấy câu trả lời chuẩn từ tập test\n",
    "\n",
    "# Lại tạo prompt theo cùng \"khuôn\" như tokenization để mô hình hiểu\n",
    "# Khuôn mẫu: Tables: <context>  Question: <question>  Answer:\n",
    "prompt = f\"\"\"Tables:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Đảm bảo model và input cùng trên một thiết bị (CPU hoặc GPU) nếu có\n",
    "inputs = tokenizer(prompt, return_tensors='pt') # Tokenize đầu vào\n",
    "inputs = inputs.to('cuda') # Chuyển input sang GPU nếu có\n",
    "\n",
    "output = tokenizer.decode( # dùng tokenizer.decode để giải mã token thành text\n",
    "    finetuned_model.generate( # dùng finetuned_model (vừa train hoặc model gốc nếu chưa train)\n",
    "        inputs[\"input_ids\"], # input_ids của prompt đã tokenized\n",
    "        max_new_tokens=200, # Giới hạn tối đa 200 token mới sinh\n",
    "    )[0], # Lấy mảng token đầu tiên trong batch (ở đây batch size=1)\n",
    "    skip_special_tokens=True # Bỏ qua các token đặc biệt khi giải mã\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN ANSWER:\\n{answer}\\n')\n",
    "print(dash_line)\n",
    "print(f'FINE-TUNED MODEL - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4408b",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 10) ĐÁNH GIÁ SƠ BỘ BẰNG ROUGE (SUBSET 25 MẪU)\n",
    "# ==============================\n",
    " Ghi chú: ROUGE đo độ “giống” chuỗi, không phải thước đo chuẩn cho SQL (Exec-Acc), nhưng dùng ở đây như chỉ báo tham khảo nhanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eca54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1115 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình định lượng bằng metric ROUGE (subset 25 mẫu do thời gian chạy lâu)\n",
    "questions = dataset['test'][0:25]['question'] # Lấy 25 câu hỏi từ tập test\n",
    "contexts = dataset['test'][0:25]['context'] # Lấy 25 context từ tập test\n",
    "human_baseline_answers = dataset['test'][0:25]['answer'] # Lấy 25 câu trả lời chuẩn từ tập test\n",
    "\n",
    "original_model_answers = [] # Lưu câu trả lời từ model gốc (baseline)\n",
    "finetuned_model_answers = [] # Lưu câu trả lời từ model đã fine-tune\n",
    "\n",
    "for idx, question in enumerate(questions): # Lặp qua từng câu hỏi trong 25 mẫu\n",
    "\n",
    "    # Tạo prompt đầu vào cho từng mẫu test theo đúng khuôn mẫu đã dùng khi train\n",
    "    prompt = f\"\"\"Tables:\n",
    "{contexts[idx]}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize prompt: chuyển prompt thành input_ids để model hiểu (dùng tokenizer đã fine-tune)\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    input_ids = input_ids.to('cuda') # Đảm bảo input nằm trên GPU (nếu có)\n",
    "\n",
    "    # Lấy đáp án chuẩn (human_baseline_text_output) để so sánh với model\n",
    "    human_baseline_text_output = human_baseline_answers[idx] \n",
    "\n",
    "    # Sinh đáp án từ model gốc (chưa fine-tune)\n",
    "    # GenerationConfig(max_new_tokens=300): giới hạn tối đa 300 token mới sinh ra (tránh sinh quá dài)\n",
    "    original_model_outputs = original_model.generate(\n",
    "        input_ids=input_ids, \n",
    "        generation_config=GenerationConfig(max_new_tokens=300)\n",
    "    )\n",
    "    # Giải mã token thành text, bỏ qua các token đặc biệt (skip_special_tokens=True)\n",
    "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "    original_model_answers.append(original_model_text_output) # Lưu kết quả vào list\n",
    "\n",
    "    # Sinh đáp án từ model đã fine-tune (huấn luyện trên tập dữ liệu SQL)\n",
    "    finetuned_model_outputs = finetuned_model.generate(\n",
    "        input_ids=input_ids, \n",
    "        generation_config=GenerationConfig(max_new_tokens=300)\n",
    "    )\n",
    "    finetuned_model_text_output = tokenizer.decode(finetuned_model_outputs[0], skip_special_tokens=True)\n",
    "    finetuned_model_answers.append(finetuned_model_text_output) # Lưu kết quả vào list\n",
    "\n",
    "# Ghép 3 loại đáp án (chuẩn, model gốc, model fine-tune) thành từng dòng để tiện so sánh\n",
    "zipped_summaries = list(zip(human_baseline_answers, original_model_answers, finetuned_model_answers))\n",
    "\n",
    "# Tạo DataFrame pandas để hiển thị kết quả so sánh từng mẫu\n",
    "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_answers', 'original_model_answers', 'finetuned_model_answers'])\n",
    "# df # (bỏ comment nếu muốn hiển thị bảng kết quả)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e0e96",
   "metadata": {},
   "source": [
    "\n",
    "Các bước phía dưới sẽ thực hiện đánh giá định lượng mô hình đã fine-tune bằng metric ROUGE trên một tập mẫu nhỏ (25 mẫu) để so sánh chất lượng sinh SQL giữa model gốc và model đã huấn luyện.  \n",
    "Sau đó, hướng dẫn cách sử dụng mô hình đã fine-tune để sinh truy vấn SQL mới (inference), và đóng gói mô hình thành file zip để tiện tải về hoặc triển khai vào ứng dụng thực tế (FastAPI, Flask, .NET...).\n",
    "\n",
    "**Tóm tắt các bước:**\n",
    "1. Đánh giá mô hình bằng ROUGE (so sánh với đáp án chuẩn).\n",
    "2. Sinh truy vấn SQL mới từ mô hình đã fine-tune (inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf01ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=eb239942ed430dd9a7751a018ff5f8b4f9e406835500de47397bb6e7fb145f08\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bed0f",
   "metadata": {},
   "source": [
    "Compute ROUGE score for this subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL MODEL:\n",
      "{'rouge1': 0.031233998975934457, 'rouge2': 0.005, 'rougeL': 0.03151917519331407, 'rougeLsum': 0.03174603174603174}\n",
      "FINE-TUNED MODEL:\n",
      "{'rouge1': 0.9200182907378598, 'rouge2': 0.9027459586080278, 'rougeL': 0.916619247172085, 'rougeLsum': 0.9139777174406729}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge') # Nạp metric ROUGE từ thư viện evaluate\n",
    "\n",
    "original_model_results = rouge.compute( # Tính toán ROUGE cho model gốc\n",
    "    predictions=original_model_answers, # Dự đoán từ model gốc\n",
    "    references=human_baseline_answers[0:len(original_model_answers)], # Đáp án chuẩn tương ứng\n",
    "    use_aggregator=True, # Sử dụng hàm tổng hợp kết quả\n",
    "    use_stemmer=True, # Sử dụng stemming để cải thiện so khớp\n",
    ")\n",
    "print('ORIGINAL MODEL:')\n",
    "print(original_model_results) # In kết quả ROUGE cho model gốc\n",
    "\n",
    "\n",
    "finetuned_model_results = rouge.compute( # Tính toán ROUGE cho model đã fine-tune\n",
    "    predictions=finetuned_model_answers, # Dự đoán từ model đã fine-tune\n",
    "    references=human_baseline_answers[0:len(finetuned_model_answers)], # Đáp án chuẩn tương ứng\n",
    "    use_aggregator=True,\n",
    "    use_stemmer=True,\n",
    ")\n",
    "print('FINE-TUNED MODEL:')\n",
    "print(finetuned_model_results) # In kết quả ROUGE cho model đã fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356d0ac",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 11) HÀM SUY LUẬN (INFERENCE) VỚI MÔ HÌNH ĐÃ FINE-TUNE\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa18f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query:\n",
      "SELECT date FROM table_name_11 WHERE away_team = \"essendon\"\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer # Model và Tokenizer T5 (nạp lại để chắc chắn)\n",
    "import torch\n",
    "\n",
    "# Nạp mô hình đã fine-tune và tokenizer từ thư mục lưu trên Kaggle\n",
    "model_path = \"sql_t5_finetuned\" # Thư mục ngay dưới /kaggle/working\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path).to('cuda')\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Hàm tiện ích để sinh truy vấn SQL từ context và question\n",
    "def generate_sql(context, question):\n",
    "    prompt = f\"\"\"Tables:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "    output = tokenizer.decode(\n",
    "        model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_new_tokens=200,\n",
    "        )[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "# Ví dụ inference với một mẫu từ tập test (phần tử đầu tiên)\n",
    "index = 0\n",
    "context = dataset['test'][index]['context']\n",
    "question = dataset['test'][index]['question']\n",
    "\n",
    "output = generate_sql(context, question)\n",
    "\n",
    "print(f\"Generated SQL Query:\\n{output}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd11a4",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "# 12) ĐÓNG GÓI MÔ HÌNH ĐỂ TẢI XUỐNG\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.115.10)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.46.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.11.0a2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.29.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (3.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Cài thêm để chạy service nếu cần (không bắt buộc)\n",
    "!pip install fastapi uvicorn transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee4afa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/sql_t5_finetuned.zip'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil # Thư viện shutil để nén file zip\n",
    "\n",
    "# Nén thư mục model đã fine-tune để tiện download từ Kaggle\n",
    "shutil.make_archive('/kaggle/working/sql_t5_finetuned', 'zip', '/kaggle/working/sql_t5_finetuned')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
